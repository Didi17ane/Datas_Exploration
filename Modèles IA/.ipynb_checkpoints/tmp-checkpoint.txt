"""
Pipeline complet de Machine Learning pour le scoring bancaire
Objectif : Prédire la bancarisation et créer un scoring intelligent
Basé sur les données EHCVM 2021 Côte d'Ivoire
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, 
                             roc_curve, precision_recall_curve, f1_score)
from sklearn.inspection import permutation_importance
import warnings
warnings.filterwarnings('ignore')

# Configuration
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ====================================================================
# 1. CHARGEMENT ET EXPLORATION DES DONNÉES
# ====================================================================

def load_data(filepath='EHCVM2021_ML_dataset_individuel.csv'):
    """Charge et explore le dataset"""
    print("="*70)
    print("CHARGEMENT DES DONNÉES")
    print("="*70)
    
    df = pd.read_csv(filepath, low_memory=False)
    print(f"✓ Dataset chargé : {df.shape[0]} lignes, {df.shape[1]} colonnes")
    
    # Aperçu
    print("\nAperçu des données :")
    print(df.head())
    
    # Info générales
    print("\nInformations générales :")
    print(df.info())
    
    # Statistiques descriptives
    print("\nStatistiques variables numériques :")
    print(df.describe())
    
    # Valeurs manquantes
    missing = df.isnull().sum()
    if missing.sum() > 0:
        print("\n⚠ Valeurs manquantes :")
        print(missing[missing > 0].sort_values(ascending=False))
    else:
        print("\n✓ Aucune valeur manquante")
    
    return df


def analyze_target(df, target='bancarise'):
    """Analyse la variable cible"""
    print("\n" + "="*70)
    print(f"ANALYSE VARIABLE CIBLE : {target}")
    print("="*70)
    
    # Distribution
    print("\nDistribution :")
    print(df[target].value_counts())
    print(f"\nTaux de bancarisation : {df[target].mean()*100:.2f}%")
    
    # Visualisation
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    # Barplot
    df[target].value_counts().plot(kind='bar', ax=axes[0], color=['salmon', 'lightgreen'])
    axes[0].set_title('Distribution de la variable cible')
    axes[0].set_xlabel('Bancarisé')
    axes[0].set_ylabel('Nombre')
    axes[0].set_xticklabels(['Non', 'Oui'], rotation=0)
    
    # Pie chart
    df[target].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%',
                                    labels=['Non bancarisé', 'Bancarisé'],
                                    colors=['salmon', 'lightgreen'])
    axes[1].set_ylabel('')
    axes[1].set_title('Proportion')
    
    plt.tight_layout()
    plt.savefig('01_distribution_cible.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("✓ Graphique sauvegardé : 01_distribution_cible.png")
    
    return df[target].mean()


def exploratory_analysis(df, target='bancarise'):
    """Analyse exploratoire détaillée"""
    print("\n" + "="*70)
    print("ANALYSE EXPLORATOIRE")
    print("="*70)
    
    # Taux de bancarisation par caractéristiques
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    
    # Par région
    tx_region = df.groupby('region')[target].mean().sort_values(ascending=False)
    tx_region.plot(kind='barh', ax=axes[0,0], color='steelblue')
    axes[0,0].set_title('Taux de bancarisation par région')
    axes[0,0].set_xlabel('Taux')
    
    # Par âge
    tx_age = df.groupby('age_grp')[target].mean()
    tx_age.plot(kind='bar', ax=axes[0,1], color='coral')
    axes[0,1].set_title('Taux de bancarisation par âge')
    axes[0,1].set_xlabel('Tranche d\'âge')
    axes[0,1].tick_params(axis='x', rotation=45)
    
    # Par sexe
    tx_sexe = df.groupby('sexe')[target].mean()
    tx_sexe.plot(kind='bar', ax=axes[0,2], color=['lightblue', 'pink'])
    axes[0,2].set_title('Taux de bancarisation par sexe')
    axes[0,2].set_xticklabels(['Homme', 'Femme'], rotation=0)
    
    # Par niveau de revenu
    tx_rev = df.groupby('rev_categorie')[target].mean()
    tx_rev.plot(kind='bar', ax=axes[1,0], color='green')
    axes[1,0].set_title('Taux de bancarisation par revenu')
    axes[1,0].set_xlabel('Catégorie de revenu')
    axes[1,0].tick_params(axis='x', rotation=45)
    
    # Par emploi formel
    tx_empl = df.groupby('empl_formel')[target].mean()
    tx_empl.plot(kind='bar', ax=axes[1,1], color=['orange', 'purple'])
    axes[1,1].set_title('Taux de bancarisation par type emploi')
    axes[1,1].set_xticklabels(['Informel', 'Formel'], rotation=0)
    
    # Par milieu
    tx_milieu = df.groupby('urbain')[target].mean()
    tx_milieu.plot(kind='bar', ax=axes[1,2], color=['brown', 'teal'])
    axes[1,2].set_title('Taux de bancarisation par milieu')
    axes[1,2].set_xticklabels(['Rural', 'Urbain'], rotation=0)
    
    plt.tight_layout()
    plt.savefig('02_analyse_exploratoire.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("✓ Graphique sauvegardé : 02_analyse_exploratoire.png")


# ====================================================================
# 2. PRÉPARATION DES DONNÉES
# ====================================================================

def prepare_features(df, target='bancarise'):
    """Prépare les features pour le ML"""
    print("\n" + "="*70)
    print("PRÉPARATION DES FEATURES")
    print("="*70)
    
    # Copie pour éviter modifications
    df_ml = df.copy()
    
    # Variables à exclure
    exclude_cols = ['idmen', 'idind', 'region', 'hhweight', target]
    
    # Sélection features numériques
    numeric_features = df_ml.select_dtypes(include=[np.number]).columns.tolist()
    numeric_features = [col for col in numeric_features if col not in exclude_cols]
    
    print(f"\n✓ {len(numeric_features)} features numériques sélectionnées")
    print("Exemples:", numeric_features[:10])
    
    # Préparation X et y
    X = df_ml[numeric_features]
    y = df_ml[target]
    
    # Gestion valeurs manquantes si nécessaire
    if X.isnull().sum().sum() > 0:
        print("\n⚠ Imputation des valeurs manquantes...")
        X = X.fillna(X.median())
    
    print(f"\n✓ X shape: {X.shape}")
    print(f"✓ y shape: {y.shape}")
    print(f"✓ Taux de bancarisation dans y: {y.mean()*100:.2f}%")
    
    return X, y, numeric_features


def split_data(X, y, test_size=0.2, random_state=42):
    """Split train/test avec stratification"""
    print("\n" + "="*70)
    print("SPLIT TRAIN/TEST")
    print("="*70)
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    print(f"\n✓ Train set: {X_train.shape[0]} lignes ({(1-test_size)*100:.0f}%)")
    print(f"  - Bancarisés: {y_train.sum()} ({y_train.mean()*100:.2f}%)")
    print(f"\n✓ Test set: {X_test.shape[0]} lignes ({test_size*100:.0f}%)")
    print(f"  - Bancarisés: {y_test.sum()} ({y_test.mean()*100:.2f}%)")
    
    return X_train, X_test, y_train, y_test


def scale_features(X_train, X_test):
    """Normalisation des features"""
    print("\n" + "="*70)
    print("NORMALISATION")
    print("="*70)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Conversion en DataFrame
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)
    
    print("✓ Features normalisées (moyenne=0, écart-type=1)")
    
    return X_train_scaled, X_test_scaled, scaler


# ====================================================================
# 3. ENTRAÎNEMENT DES MODÈLES
# ====================================================================

def train_models(X_train, y_train):
    """Entraîne plusieurs modèles"""
    print("\n" + "="*70)
    print("ENTRAÎNEMENT DES MODÈLES")
    print("="*70)
    
    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, 
                                                class_weight='balanced', max_depth=10),
        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42, 
                                                        max_depth=5, learning_rate=0.1)
    }
    
    trained_models = {}
    cv_scores = {}
    
    # Cross-validation
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    for name, model in models.items():
        print(f"\n{'='*50}")
        print(f"Entraînement : {name}")
        print(f"{'='*50}")
        
        # Entraînement
        model.fit(X_train, y_train)
        trained_models[name] = model
        
        # Cross-validation
        scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')
        cv_scores[name] = scores
        
        print(f"✓ Modèle entraîné")
        print(f"  ROC-AUC CV (5-fold) : {scores.mean():.4f} (+/- {scores.std()*2:.4f})")
    
    return trained_models, cv_scores


# ====================================================================
# 4. ÉVALUATION DES MODÈLES
# ====================================================================

def evaluate_models(models, X_test, y_test):
    """Évalue les modèles sur le test set"""
    print("\n" + "="*70)
    print("ÉVALUATION SUR TEST SET")
    print("="*70)
    
    results = {}
    
    for name, model in models.items():
        print(f"\n{'='*50}")
        print(f"Évaluation : {name}")
        print(f"{'='*50}")
        
        # Prédictions
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        
        # Métriques
        roc_auc = roc_auc_score(y_test, y_pred_proba)
        f1 = f1_score(y_test, y_pred)
        
        results[name] = {
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba,
            'roc_auc': roc_auc,
            'f1': f1
        }
        
        print(f"\nROC-AUC: {roc_auc:.4f}")
        print(f"F1-Score: {f1:.4f}")
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred, 
                                    target_names=['Non bancarisé', 'Bancarisé']))
        
        # Matrice de confusion
        cm = confusion_matrix(y_test, y_pred)
        print("\nMatrice de confusion:")
        print(cm)
    
    return results


def plot_roc_curves(models, results, y_test):
    """Trace les courbes ROC"""
    plt.figure(figsize=(10, 8))
    
    for name, res in results.items():
        fpr, tpr, _ = roc_curve(y_test, res['y_pred_proba'])
        plt.plot(fpr, tpr, label=f"{name} (AUC = {res['roc_auc']:.3f})", linewidth=2)
    
    plt.plot([0, 1], [0, 1], 'k--', label='Hasard (AUC = 0.5)', linewidth=1)
    plt.xlabel('Taux de Faux Positifs', fontsize=12)
    plt.ylabel('Taux de Vrais Positifs', fontsize=12)
    plt.title('Courbes ROC - Comparaison des Modèles', fontsize=14, fontweight='bold')
    plt.legend(loc='lower right', fontsize=10)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.savefig('03_roc_curves.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("\n✓ Graphique sauvegardé : 03_roc_curves.png")


def plot_feature_importance(model, feature_names, model_name='Random Forest', top_n=20):
    """Visualise l'importance des features"""
    
    if hasattr(model, 'feature_importances_'):
        importances = model.feature_importances_
    else:
        print(f"⚠ {model_name} ne supporte pas feature_importances_")
        return
    
    # Créer DataFrame
    feat_imp = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=False).head(top_n)
    
    # Visualisation
    plt.figure(figsize=(10, 8))
    plt.barh(range(len(feat_imp)), feat_imp['importance'], color='steelblue')
    plt.yticks(range(len(feat_imp)), feat_imp['feature'])
    plt.xlabel('Importance', fontsize=12)
    plt.title(f'Top {top_n}